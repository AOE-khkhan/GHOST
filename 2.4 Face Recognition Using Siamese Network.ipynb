{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Using Siamese Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will understand the siamese network by building the face recognition model. The objective of our network is to understand whether two faces are similar or dissimilar. We use AT & T's the Database of Faces which can be downloaded from here (https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html)\n",
    "\n",
    "Once you have downloaded and extracted the archive, you can see the folders like s1, s2 up to s40 as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Input, Lambda, Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.measure import compare_ssim as get_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define another function get_data for generating our data. As we know, for the Siamese network, data should be in the form of pairs (genuine and imposite) with a binary label.\n",
    "\n",
    "First, we read the images (img1, img2) from the same directory and store them in the x_genuine_pair array and assign y_genuine to 1. Next, we read the images (img1, img2) from the different directory and store them in the x_imposite pair and assign y_imposite to 0.\n",
    "\n",
    "Finally, we concatenate both x_genuine_pair, x_imposite to X and y_genuine, y_imposite to Y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ch=None):\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    #total size\n",
    "    total_sample_size = len(x_train)\n",
    "    \n",
    "    #get the new size\n",
    "    dim1 = x_train[0].shape[0]\n",
    "    dim2 = x_train[0].shape[1]\n",
    "\n",
    "    #initialize the numpy array with the shape of [total_sample, no_of_pairs, dim1, dim2]\n",
    "    x_pair = np.zeros([total_sample_size, 2, dim1, dim2, 1])  # 2 is for pairs\n",
    "    y = np.zeros([total_sample_size, 2])  # 2 is for pairs\n",
    "\n",
    "    #all indices of the images\n",
    "    indices = np.array(range(total_sample_size))\n",
    "    \n",
    "    #store the images to the initialized numpy array\n",
    "    np.random.shuffle(indices)\n",
    "    order1 = indices.copy()\n",
    "    x_pair[:, 0, :, :, 0] = x_train[order1]\n",
    "    \n",
    "    np.random.shuffle(indices)\n",
    "    order2 = indices.copy()\n",
    "    x_pair[:, 1, :, :, 0] = x_train[order2]\n",
    "\n",
    "    #the proposed similarities by ssim\n",
    "    for i in range(total_sample_size):\n",
    "        y[i][1] = 0 if y_train[order1[i]] == y_train[order2[i]] else 1\n",
    "        y[i][0] = 1 - get_similarity(\n",
    "            x_pair[:, 0][i],\n",
    "            x_pair[:, 1][i],\n",
    "            multichannel=True\n",
    "        )\n",
    "        \n",
    "    return x_pair, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2, 28, 28, 1)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20a812b3400>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[image_index, 0, :, :, 0]/255, vmin=0, vmax=1, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20a81306b38>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[image_index, 1, :, :, 0]/255, vmin=0, vmax=1, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83406944, 1.        ])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[image_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split our data for training and testing with 75% training and 25% testing proportions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95638861, 1.        ],\n",
       "       [0.89594004, 1.        ],\n",
       "       [0.82129111, 1.        ],\n",
       "       ...,\n",
       "       [0.49350389, 0.        ],\n",
       "       [0.71729424, 1.        ],\n",
       "       [0.58660328, 1.        ]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, Y_train, Y_test = train_test_split(X, Y, test_size=.25)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual_train = np.expand_dims(Y_train[:, 1], axis=1)\n",
    "y_actual_test = np.expand_dims(Y_test[:, 1], axis=1)\n",
    "\n",
    "y_train = np.expand_dims(Y_train[:, 0], axis=1)\n",
    "y_test = np.expand_dims(Y_test[:, 0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mse = 255**2\n",
    "\n",
    "def get_similarity(img1, img2, multichannel=None):\n",
    "    return ((img1 - img2)**2).mean() / max_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix(1)\n",
      "==================\n",
      "[[50.  0.]\n",
      " [50.  0.]]\n",
      "0 similar and 0 dissimilar loaded\n",
      "50.0 similar and 50.0 dissimilar processed\n",
      "accuracy = 0.5, result = [1. 0.]\n",
      "\n",
      "Confusion Matrix(2)\n",
      "==================\n",
      "[[50.  0.]\n",
      " [50.  0.]]\n",
      "0 similar and 0 dissimilar loaded\n",
      "50.0 similar and 50.0 dissimilar processed\n",
      "accuracy = 0.5, result = [1. 0.]\n",
      "\n",
      "Confusion Matrix(3)\n",
      "==================\n",
      "[[50.  0.]\n",
      " [50.  0.]]\n",
      "0 similar and 0 dissimilar loaded\n",
      "50.0 similar and 50.0 dissimilar processed\n",
      "accuracy = 0.5, result = [1. 0.]\n",
      "\n",
      "average_accuracy = 0.5\n"
     ]
    }
   ],
   "source": [
    "sample_size = 100\n",
    "n_iters = 3\n",
    "\n",
    "upper_bound_threshold = 0.0075\n",
    "lower_bound_threshold = 0.01\n",
    "\n",
    "\n",
    "ss = int(sample_size/2)\n",
    "\n",
    "similar_pairs_indices = np.where(Y_test[:, 1] == 0)[0]\n",
    "dissimilar_pairs_indices = np.where(Y_test[:, 1] == 1)[0]\n",
    "\n",
    "accuracys = []\n",
    "\n",
    "for n_iter in range(n_iters):\n",
    "    np.random.shuffle(similar_pairs_indices)\n",
    "    np.random.shuffle(dissimilar_pairs_indices)\n",
    "\n",
    "    pairs_indices = np.concatenate([similar_pairs_indices[:ss], dissimilar_pairs_indices[:ss]], axis=0)\n",
    "    np.random.shuffle(pairs_indices)\n",
    "\n",
    "    image_pairs = x_test[pairs_indices, 0]\n",
    "\n",
    "    similar = []\n",
    "    dissimilar = []\n",
    "\n",
    "    confusion_matrix = np.zeros((2, 2))\n",
    "\n",
    "    for i, img in enumerate(image_pairs):\n",
    "        best_sim = best_sim_index = None\n",
    "\n",
    "        for j, imgx in enumerate(image_pairs):\n",
    "            if i == j:\n",
    "                continue\n",
    "\n",
    "            sim = get_similarity(img, imgx, multichannel=True) \n",
    "#             print(sim)\n",
    "\n",
    "            if best_sim is None:\n",
    "                best_sim = sim\n",
    "                best_sim_index = pairs_indices[j]\n",
    "\n",
    "            elif sim > best_sim:\n",
    "                best_sim = sim\n",
    "                best_sim_index = pairs_indices[j]\n",
    "        \n",
    "        #the actual difference\n",
    "        actual = int(Y_test[pairs_indices[i], 1])\n",
    "        \n",
    "        #checking for right and wrong\n",
    "        if best_sim > upper_bound_threshold:\n",
    "            prediction = 0\n",
    "            \n",
    "        elif best_sim < lower_bound_threshold:\n",
    "            prediction = 1\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        #update conf matrix\n",
    "        confusion_matrix[actual][prediction] += 1\n",
    "        \n",
    "    similar = np.array(similar)\n",
    "    dissimilar = np.array(dissimilar)\n",
    "\n",
    "    s1, s2 = confusion_matrix.sum(1)\n",
    "    \n",
    "    result = (confusion_matrix * np.diag((1, 1))).sum(1) / np.array([s1, s2])\n",
    "    accuracy = result.mean()\n",
    "    \n",
    "    accuracys.append(accuracy)\n",
    "\n",
    "    print(f\"Confusion Matrix({n_iter+1})\\n==================\")\n",
    "    print(confusion_matrix)\n",
    "\n",
    "    print(f\"{len(similar)} similar and {len(dissimilar)} dissimilar loaded\")\n",
    "    print(f\"{s1} similar and {s2} dissimilar processed\")\n",
    "\n",
    "    print(f\"accuracy = {accuracy}, result = {result}\\n\")\n",
    "\n",
    "print(f\"average_accuracy = {np.array(accuracys).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20a8136db38>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.ones(len(similar)), similar, c='g', marker='o', label='similar')\n",
    "plt.scatter(np.zeros(len(dissimilar)), dissimilar, c='r', marker='x', label='dissimilar')\n",
    "plt.legend(loc='upper center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that, we have successfully generated our data, we build our siamese network. First, we define the base network which is basically a convolutional network used for feature extraction. We build two convolutional layers with rectified linear unit (ReLU) activations and max pooling followed by flat layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_network(input_shape):\n",
    "    \n",
    "    seq = Sequential()\n",
    "    \n",
    "    nb_filter = [6, 12]\n",
    "    kernel_size = 3\n",
    "    \n",
    "    \n",
    "    #convolutional layer 1\n",
    "    seq.add(Conv2D(nb_filter[0], (kernel_size, kernel_size), input_shape=input_shape, padding='valid'))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    seq.add(Dropout(.25))\n",
    "    \n",
    "    #convolutional layer 2\n",
    "    seq.add(Conv2D(nb_filter[1], (kernel_size, kernel_size), padding='valid'))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "    seq.add(Dropout(.25))\n",
    "\n",
    "    #flatten \n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(128, activation='relu'))\n",
    "    seq.add(Dropout(0.1))\n",
    "    seq.add(Dense(50, activation='relu'))\n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we feed the image pair, to the base network, which will return the embeddings that is, feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[2:]\n",
    "img_a = Input(shape=input_dim)\n",
    "img_b = Input(shape=input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network = build_base_network(input_dim)\n",
    "feat_vecs_a = base_network(img_a)\n",
    "feat_vecs_b = base_network(img_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These feat_vecs_a and feat_vecs_b are the feature vectors of our image pair. Next, we feed this feature vectors to the energy function to compute the distance between them, we use Euclidean distance as our energy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, we set the epoch length to 13 and we use RMS prop for optimization and define our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 64\n",
    "rms = RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[img_a, img_b], outputs=distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our loss function as contrastive_loss function and compile the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    return labels[predictions.ravel() < 0.5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=contrastive_loss, optimizer=rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we generate our data and check our data size. As you can see we have 20,000 data points, out of these 10,000 are genuine pairs and 10,000 are imposite pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = x_train[start:start+step, 0]\n",
    "img2 = x_train[start:start+step, 1]\n",
    "similarity = y_train[start:start+step, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 25 samples\n",
      "Epoch 1/64\n",
      " - 1s - loss: 0.0304 - val_loss: 0.0894\n",
      "Epoch 2/64\n",
      " - 0s - loss: 0.0434 - val_loss: 0.0864\n",
      "Epoch 3/64\n",
      " - 0s - loss: 0.0279 - val_loss: 0.0733\n",
      "Epoch 4/64\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0808\n",
      "Epoch 5/64\n",
      " - 0s - loss: 0.0224 - val_loss: 0.0862\n",
      "Epoch 6/64\n",
      " - 0s - loss: 0.0129 - val_loss: 0.0806\n",
      "Epoch 7/64\n",
      " - 0s - loss: 0.0298 - val_loss: 0.0926\n",
      "Epoch 8/64\n",
      " - 0s - loss: 0.0283 - val_loss: 0.0884\n",
      "Epoch 9/64\n",
      " - 0s - loss: 0.0075 - val_loss: 0.0999\n",
      "Epoch 10/64\n",
      " - 0s - loss: 0.0235 - val_loss: 0.0643\n",
      "Epoch 11/64\n",
      " - 0s - loss: 0.0171 - val_loss: 0.1113\n",
      "Epoch 12/64\n",
      " - 0s - loss: 0.0246 - val_loss: 0.0846\n",
      "Epoch 13/64\n",
      " - 0s - loss: 0.0149 - val_loss: 0.1014\n",
      "Epoch 14/64\n",
      " - 0s - loss: 0.0284 - val_loss: 0.0972\n",
      "Epoch 15/64\n",
      " - 0s - loss: 0.0128 - val_loss: 0.0817\n",
      "Epoch 16/64\n",
      " - 0s - loss: 0.0131 - val_loss: 0.0823\n",
      "Epoch 17/64\n",
      " - 0s - loss: 0.0069 - val_loss: 0.0857\n",
      "Epoch 18/64\n",
      " - 0s - loss: 0.0096 - val_loss: 0.0834\n",
      "Epoch 19/64\n",
      " - 0s - loss: 0.0202 - val_loss: 0.0792\n",
      "Epoch 20/64\n",
      " - 0s - loss: 0.0196 - val_loss: 0.0732\n",
      "Epoch 21/64\n",
      " - 0s - loss: 0.0111 - val_loss: 0.0858\n",
      "Epoch 22/64\n",
      " - 0s - loss: 0.0022 - val_loss: 0.0900\n",
      "Epoch 23/64\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0826\n",
      "Epoch 24/64\n",
      " - 0s - loss: 0.0093 - val_loss: 0.0999\n",
      "Epoch 25/64\n",
      " - 0s - loss: 0.0265 - val_loss: 0.0828\n",
      "Epoch 26/64\n",
      " - 0s - loss: 0.0058 - val_loss: 0.0964\n",
      "Epoch 27/64\n",
      " - 0s - loss: 0.0104 - val_loss: 0.0825\n",
      "Epoch 28/64\n",
      " - 0s - loss: 0.0091 - val_loss: 0.0906\n",
      "Epoch 29/64\n",
      " - 0s - loss: 0.0096 - val_loss: 0.0856\n",
      "Epoch 30/64\n",
      " - 0s - loss: 0.0120 - val_loss: 0.0827\n",
      "Epoch 31/64\n",
      " - 0s - loss: 0.0129 - val_loss: 0.0822\n",
      "Epoch 32/64\n",
      " - 0s - loss: 0.0046 - val_loss: 0.0869\n",
      "Epoch 33/64\n",
      " - 0s - loss: 0.0024 - val_loss: 0.0912\n",
      "Epoch 34/64\n",
      " - 0s - loss: 0.0072 - val_loss: 0.0930\n",
      "Epoch 35/64\n",
      " - 0s - loss: 0.0036 - val_loss: 0.0803\n",
      "Epoch 36/64\n",
      " - 0s - loss: 0.0109 - val_loss: 0.0794\n",
      "Epoch 37/64\n",
      " - 0s - loss: 0.0049 - val_loss: 0.0706\n",
      "Epoch 38/64\n",
      " - 0s - loss: 0.0104 - val_loss: 0.0738\n",
      "Epoch 39/64\n",
      " - 0s - loss: 0.0231 - val_loss: 0.0857\n",
      "Epoch 40/64\n",
      " - 0s - loss: 0.0055 - val_loss: 0.0713\n",
      "Epoch 41/64\n",
      " - 0s - loss: 0.0058 - val_loss: 0.0872\n",
      "Epoch 42/64\n",
      " - 0s - loss: 0.0026 - val_loss: 0.0820\n",
      "Epoch 43/64\n",
      " - 0s - loss: 0.0084 - val_loss: 0.0924\n",
      "Epoch 44/64\n",
      " - 0s - loss: 0.0115 - val_loss: 0.0814\n",
      "Epoch 45/64\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0796\n",
      "Epoch 46/64\n",
      " - 0s - loss: 0.0094 - val_loss: 0.0753\n",
      "Epoch 47/64\n",
      " - 0s - loss: 0.0043 - val_loss: 0.0782\n",
      "Epoch 48/64\n",
      " - 0s - loss: 0.0038 - val_loss: 0.0789\n",
      "Epoch 49/64\n",
      " - 0s - loss: 0.0054 - val_loss: 0.0754\n",
      "Epoch 50/64\n",
      " - 0s - loss: 0.0024 - val_loss: 0.1081\n",
      "Epoch 51/64\n",
      " - 0s - loss: 0.0083 - val_loss: 0.0653\n",
      "Epoch 52/64\n",
      " - 0s - loss: 0.0053 - val_loss: 0.0747\n",
      "Epoch 53/64\n",
      " - 0s - loss: 0.0086 - val_loss: 0.0779\n",
      "Epoch 54/64\n",
      " - 0s - loss: 0.0038 - val_loss: 0.0708\n",
      "Epoch 55/64\n",
      " - 0s - loss: 0.0054 - val_loss: 0.0908\n",
      "Epoch 56/64\n",
      " - 0s - loss: 0.0261 - val_loss: 0.0723\n",
      "Epoch 57/64\n",
      " - 0s - loss: 0.0021 - val_loss: 0.0696\n",
      "Epoch 58/64\n",
      " - 0s - loss: 0.0025 - val_loss: 0.0798\n",
      "Epoch 59/64\n",
      " - 0s - loss: 0.0049 - val_loss: 0.0693\n",
      "Epoch 60/64\n",
      " - 0s - loss: 6.3517e-04 - val_loss: 0.0747\n",
      "Epoch 61/64\n",
      " - 0s - loss: 0.0078 - val_loss: 0.0766\n",
      "Epoch 62/64\n",
      " - 0s - loss: 1.8374e-04 - val_loss: 0.0793\n",
      "Epoch 63/64\n",
      " - 0s - loss: 0.0080 - val_loss: 0.0531\n",
      "Epoch 64/64\n",
      " - 0s - loss: 0.0154 - val_loss: 0.0853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a03ee176d8>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([img_1, img2], similarity, validation_split=.25, batch_size=16, verbose=2, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make predictions with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7641968631692807"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict([x_test[:, 0], x_test[:, 1]])\n",
    "compute_accuracy(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 50)           45698       input_17[0][0]                   \n",
      "                                                                 input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           sequential_8[1][0]               \n",
      "                                                                 sequential_8[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 45,698\n",
      "Trainable params: 45,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
